from __future__ import annotations

import json
import logging
import re
from typing import List, Tuple, Optional

from openai import OpenAI, Stream
from openai.types.chat import ChatCompletionChunk

from config.settings import OpenAISettings
from content.application.port.embedding_generator_port import EmbeddingGeneratorPort
from content.application.port.embedding_repository_port import EmbeddingRepositoryPort
from content.application.port.video_repository_port import VideoRepositoryPort
from content.domain.video_analysis import VideoAnalysisResult

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)

class GuideChatUseCase:
    """
    ì˜ìƒ ë¶„ì„ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ê°€ì´ë“œë¥¼ ì œê³µí•˜ëŠ” ìœ ìŠ¤ì¼€ì´ìŠ¤.
    - ì§ˆë¬¸ê³¼ ìœ ì‚¬í•œ ì˜ìƒ ë‚´ êµ¬ê°„(í…ìŠ¤íŠ¸/ì‹œê° ì •ë³´)ì„ ê²€ìƒ‰í•˜ì—¬ GPT ì»¨í…ìŠ¤íŠ¸ë¡œ ì œê³µ.
    """

    def __init__(
        self,
        embedding_generator: EmbeddingGeneratorPort,
        embedding_repository: EmbeddingRepositoryPort,
        video_repository: VideoRepositoryPort,
        settings: OpenAISettings | None = None,
    ):
        self.embedding_generator = embedding_generator
        self.embedding_repository = embedding_repository
        self.video_repository = video_repository
        self.settings = settings or OpenAISettings()
        if not self.settings.api_key:
            raise ValueError("OPENAI_API_KEY is required for GuideChatUseCase")
        self.client = OpenAI(api_key=self.settings.api_key)

    def _parse_duration_to_seconds(self, duration: Optional[str]) -> Optional[int]:
        """ISO 8601 duration (PT1M30S) ë˜ëŠ” ì´ˆ ë‹¨ìœ„ ë¬¸ìì—´ì„ ì´ˆ ë‹¨ìœ„ ì •ìˆ˜ë¡œ ë³€í™˜"""
        if not duration:
            return None
        
        # ì´ë¯¸ ìˆ«ìì¸ ê²½ìš°
        if duration.isdigit():
            return int(duration)
        
        # ISO 8601 í˜•ì‹ (PT1H2M30S)
        match = re.match(r'PT(?:(\d+)H)?(?:(\d+)M)?(?:(\d+)S)?', duration)
        if match:
            hours = int(match.group(1) or 0)
            minutes = int(match.group(2) or 0)
            seconds = int(match.group(3) or 0)
            return hours * 3600 + minutes * 60 + seconds
        
        return None

    def _classify_video_type(self, duration_seconds: Optional[int]) -> str:
        """ì˜ìƒ ê¸¸ì´ì— ë”°ë¼ ìœ í˜• ë¶„ë¥˜"""
        if duration_seconds is None:
            return "ì˜ìƒ"
        elif duration_seconds <= 60:
            return "ìˆì¸ (60ì´ˆ ì´í•˜ ì§§ì€ ì˜ìƒ)"
        elif duration_seconds <= 180:
            return "ì§§ì€ ì˜ìƒ(1~3ë¶„)"
        elif duration_seconds <= 600:
            return "ì¤‘ê°„ ê¸¸ì´ ì˜ìƒ(3~10ë¶„)"
        else:
            return "ê¸´ ì˜ìƒ(10ë¶„ ì´ìƒ)"

    async def answer_with_guide(
        self,
        user_messages: List[dict],
        video_id: Optional[str] = None,
        limit: int = 20
    ) -> Stream[ChatCompletionChunk]:
        # 1. ìœ ì € ì§ˆë¬¸ ì¶”ì¶œ
        query = ""
        for msg in reversed(user_messages):
            if msg.get("role") == "user":
                query = msg.get("content", "")
                break

        if not query:
            raise ValueError("User query is missing")

        # 2. ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± ë° ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘
        context_text = ""
        case_infos = []  # (title, duration_seconds, duration_str) ë¦¬ìŠ¤íŠ¸
        
        # [Path A] íŠ¹ì • ì˜ìƒì— ëŒ€í•œ ìƒì„¸ ê°€ì´ë“œ ìš”ì²­
        target_video_id = video_id
        if not target_video_id:
            ref_keywords = ["ì € ì˜ìƒ", "ê·¸ ì˜ìƒ", "ì¶”ì²œí•´ì¤€", "ì´ê±°", "ê·¸ê±°", "ì–´ë–»ê²Œ ë§Œë“œ", "ì œì‘", "ë°©ë²•", "ì•Œë ¤"]
            if any(k in query for k in ref_keywords):
                for msg in reversed(user_messages):
                    if msg.get("role") == "assistant":
                        videos = msg.get("videos")
                        if videos and isinstance(videos, list) and len(videos) > 0:
                            # ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ ì˜ìƒ ì œëª© í‚¤ì›Œë“œ ë§¤ì¹­ ì‹œë„
                            matched_video = self._match_video_by_title(query, videos)
                            if matched_video:
                                target_video_id = matched_video.get("video_id")
                                logger.info(f"[GuideChatUseCase] ì œëª© ë§¤ì¹­ìœ¼ë¡œ ì˜ìƒ ID ì¶”ì¶œ: {target_video_id} (ì œëª©: {matched_video.get('title')})")
                            else:
                                # ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ ì²« ë²ˆì§¸ ì˜ìƒ ì„ íƒ
                                target_video_id = videos[0].get("video_id")
                                logger.info(f"[GuideChatUseCase] ì œëª© ë§¤ì¹­ ì‹¤íŒ¨, ì²« ë²ˆì§¸ ì˜ìƒ ì„ íƒ: {target_video_id}")
                            break

        if target_video_id and target_video_id != "all":
            logger.info(f"[GuideChatUseCase] Path A - íŠ¹ì • ì˜ìƒ ê°€ì´ë“œ ìš”ì²­: {target_video_id}")
            analysis = await self.video_repository.get_analysis(target_video_id)
            if analysis:
                duration_sec = self._parse_duration_to_seconds(analysis.video_duration)
                case_infos.append((analysis.video_title or "ì œëª© ì—†ìŒ", duration_sec, analysis.video_duration))
                context_text = self._build_structural_summary(analysis, case_number=1)
                logger.info(f"[GuideChatUseCase] ì˜ìƒ ID: {target_video_id}, ì œëª©: {analysis.video_title or 'ì œëª©ì—†ìŒ'}, ê¸¸ì´: {analysis.video_duration} - DB ë°ì´í„° ë¡œë“œ ì„±ê³µ")
            else:
                context_text = f"ìš”ì²­í•˜ì‹  ì˜ìƒ(ID: {target_video_id})ì˜ ë¶„ì„ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                logger.warning(f"[GuideChatUseCase] ì˜ìƒ ID: {target_video_id} - DB ë¶„ì„ ë°ì´í„° ì—†ìŒ")
        
        # [Path B] ì œì‘ ë°©ë²• íŒ¨í„´ ë¶„ì„ (ì „ì²´ ì˜ìƒ êµ¬ì¡° ê¸°ë°˜)
        else:
            query_embedding = await self.embedding_generator.generate_embedding(query)
            similar_chunks = await self.embedding_repository.search_similar(
                query_embedding=query_embedding,
                limit=limit
            )
            
            logger.info(f"[GuideChatUseCase] ì¿¼ë¦¬: '{query}'")
            logger.info(f"[GuideChatUseCase] ìœ ì‚¬ ì²­í¬ ê²€ìƒ‰ ê²°ê³¼: {len(similar_chunks)}ê°œ")
            
            video_scores = {}
            for c in similar_chunks:
                vid = c.get('video_id')
                if vid:
                    video_scores[vid] = video_scores.get(vid, 0) + c.get('similarity', 0)
            
            top_video_ids = sorted(video_scores.keys(), key=lambda v: video_scores[v], reverse=True)[:3]
            
            logger.info(f"[GuideChatUseCase] ìƒìœ„ ì˜ìƒ ID ë° ì ìˆ˜: {[(vid, video_scores[vid]) for vid in top_video_ids]}")
            
            if not top_video_ids:
                context_text = "ê´€ë ¨ëœ ì˜ìƒì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ì œì‘ ê°€ì´ë“œë¥¼ ì œê³µí•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤."
                logger.warning("[GuideChatUseCase] ê´€ë ¨ ì˜ìƒì„ ì°¾ì§€ ëª»í•¨ - DB ë¶„ì„ ë°ì´í„° ë¯¸ì‚¬ìš©")
            else:
                full_contexts = []
                for idx, vid in enumerate(top_video_ids, start=1):
                    analysis = await self.video_repository.get_analysis(vid)
                    if analysis:
                        duration_sec = self._parse_duration_to_seconds(analysis.video_duration)
                        case_infos.append((analysis.video_title or "ì œëª© ì—†ìŒ", duration_sec, analysis.video_duration))
                        summary = self._build_structural_summary(analysis, case_number=idx)
                        full_contexts.append(summary)
                        logger.info(f"[GuideChatUseCase] ì‚¬ë¡€{idx} - video_id: {vid}, ì œëª©: {analysis.video_title or 'ì œëª©ì—†ìŒ'}, ê¸¸ì´: {analysis.video_duration} - DB ë°ì´í„° ë¡œë“œ ì„±ê³µ")
                    else:
                        logger.warning(f"[GuideChatUseCase] ì‚¬ë¡€{idx} - video_id: {vid} - DB ë¶„ì„ ë°ì´í„° ì—†ìŒ")
                
                if full_contexts:
                    context_text = "\n\n".join(full_contexts)
                    logger.info(f"[GuideChatUseCase] ì´ {len(full_contexts)}ê°œ ì‚¬ë¡€ì˜ ë¶„ì„ ë°ì´í„° ì‚¬ìš©")
                else:
                    context_text = "ì˜ìƒ IDëŠ” ì‹ë³„ë˜ì—ˆìœ¼ë‚˜ ë¶„ì„ ë°ì´í„°ê°€ ì—†ì–´ ì œì‘ ê°€ì´ë“œë¥¼ ì œê³µí•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤."
                    logger.warning("[GuideChatUseCase] ëª¨ë“  ì˜ìƒì˜ ë¶„ì„ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨ - DB ë¶„ì„ ë°ì´í„° ë¯¸ì‚¬ìš©")
            
        logger.info(f"[GuideChatUseCase] ìµœì¢… ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´: {len(context_text)} chars")
        
        # 3. ë™ì  ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±
        system_prompt = self._build_dynamic_prompt(case_infos)

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "system", "content": f"### ë²¤ì¹˜ë§ˆí‚¹ ëŒ€ìƒ ì˜ìƒ ë¶„ì„ ë°ì´í„°:\n{context_text}"},
        ] + user_messages

        # 4. OpenAI Completion ìƒì„±
        stream = self.client.chat.completions.create(
            model=self.settings.model or "gpt-4o",
            messages=messages,
            stream=True
        )

        return stream

    def _match_video_by_title(self, query: str, videos: List[dict]) -> Optional[dict]:
        """ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ ì˜ìƒ ì œëª© í‚¤ì›Œë“œë¥¼ ë§¤ì¹­í•˜ì—¬ í•´ë‹¹ ì˜ìƒ ë°˜í™˜"""
        query_lower = query.lower()
        
        best_match = None
        best_score = 0
        
        for video in videos:
            title = video.get("title", "")
            if not title:
                continue
            
            # ì œëª©ì„ í‚¤ì›Œë“œë¡œ ë¶„ë¦¬ (ê³µë°±, íŠ¹ìˆ˜ë¬¸ì ê¸°ì¤€)
            title_keywords = re.split(r'[\s\-\[\]\(\):\|,]+', title.lower())
            title_keywords = [k for k in title_keywords if len(k) >= 2]  # 2ê¸€ì ì´ìƒë§Œ
            
            # ì¿¼ë¦¬ì— í¬í•¨ëœ í‚¤ì›Œë“œ ìˆ˜ ê³„ì‚°
            match_count = sum(1 for kw in title_keywords if kw in query_lower)
            
            # ê°€ì¥ ë§ì´ ë§¤ì¹­ëœ ì˜ìƒ ì„ íƒ (ìµœì†Œ 1ê°œ ì´ìƒ ë§¤ì¹­ í•„ìš”)
            if match_count > best_score:
                best_score = match_count
                best_match = video
                
        if best_match:
            logger.info(f"[GuideChatUseCase] ì œëª© ë§¤ì¹­ ì„±ê³µ: '{best_match.get('title')}' (ë§¤ì¹­ í‚¤ì›Œë“œ ìˆ˜: {best_score})")
        
        return best_match

    def _build_dynamic_prompt(self, case_infos: List[Tuple[str, Optional[int], Optional[str]]]) -> str:
        """ì‚¬ë¡€ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë™ì ì¸ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        case_count = len(case_infos)
        
        if case_count == 0:
            return (
                "ë‹¹ì‹ ì€ 'ì˜ìƒ ì½˜í…ì¸  ì œì‘ ì „ëµê°€'ì…ë‹ˆë‹¤. "
                "ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì¼ë°˜ì ì¸ ì˜ìƒ ì œì‘ ê°€ì´ë“œë¥¼ ì œê³µí•´ ì£¼ì„¸ìš”. "
                "ë‹¨, í˜„ì¬ ë¶„ì„ëœ ì‚¬ë¡€ ë°ì´í„°ê°€ ì—†ìœ¼ë¯€ë¡œ ì¼ë°˜ë¡ ì ì¸ ì¡°ì–¸ë§Œ ê°€ëŠ¥í•¨ì„ ì•ˆë‚´í•˜ì„¸ìš”."
            )
        
        # ì˜ìƒ ìœ í˜• íŒë‹¨ (ì²« ë²ˆì§¸ ì‚¬ë¡€ ê¸°ì¤€, ë˜ëŠ” í‰ê· )
        durations = [d for (_, d, _) in case_infos if d is not None]
        avg_duration = sum(durations) / len(durations) if durations else None
        video_type = self._classify_video_type(avg_duration)
        
        # ì‚¬ë¡€ ëª©ë¡ ìƒì„±
        case_list = "\n".join([
            f"  - ì‚¬ë¡€ {i+1}: \"{title}\" (ê¸¸ì´: {dur_str or 'ì•Œ ìˆ˜ ì—†ìŒ'})"
            for i, (title, _, dur_str) in enumerate(case_infos)
        ])
        
        return f"""ë‹¹ì‹ ì€ '{video_type} ì½˜í…ì¸  ì œì‘ ì „ëµê°€'ì…ë‹ˆë‹¤.

âš ï¸ **ì¤‘ìš” ì œì•½ì‚¬í•­**:
- ì œê³µëœ ë¶„ì„ ë°ì´í„°ëŠ” **ì´ {case_count}ê°œ ì‚¬ë¡€**ì…ë‹ˆë‹¤:
{case_list}
- **ë°˜ë“œì‹œ ì œê³µëœ ì‚¬ë¡€ë§Œ ì°¸ì¡°**í•˜ì„¸ìš”. ì¡´ì¬í•˜ì§€ ì•ŠëŠ” "ì‚¬ë¡€ {case_count + 1}" ë“±ì„ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”.
- ì‚¬ë¡€ë¥¼ ì¸ìš©í•  ë•Œ **"ì‚¬ë¡€ 1 (ì˜ìƒì œëª©)"** í˜•íƒœë¡œ ì œëª©ë„ í•¨ê»˜ ëª…ì‹œí•˜ì„¸ìš”.

ğŸ“‹ **ë‹µë³€ ê°€ì´ë“œ**:
1. **ì˜ìƒ ìœ í˜• ë§ì¶¤ ì¡°ì–¸**: ì´ ì˜ìƒì€ {video_type}ì…ë‹ˆë‹¤. í•´ë‹¹ ìœ í˜•ì— ì í•©í•œ êµ¬ì¡°ì™€ ì—°ì¶œì„ ì œì•ˆí•˜ì„¸ìš”.
2. **êµ¬ì¡°ì  íŒ¨í„´ ë¶„ì„**: ë„ì…ë¶€, ë³¸ë¡ , ê²°ë§ì˜ íë¦„ì„ ë¶„ì„í•˜ì„¸ìš”.
3. **êµ¬ì²´ì  ì‹¤í–‰ ê°€ì´ë“œ**: ì‹œê°„ëŒ€ë³„ êµ¬ì²´ì ì¸ ì§€ì¹¨ì„ ì£¼ì„¸ìš” (ì˜ˆ: "0~10ì´ˆ: í›…ìœ¼ë¡œ ì‹œì‘").
4. **ê·¼ê±° ì œì‹œ**: ì œê³µëœ ì‚¬ë¡€ ë°ì´í„°ë¥¼ ì¸ìš©í•˜ì—¬ ê·¼ê±°ë¥¼ ëª…í™•íˆ í•˜ì„¸ìš”.
5. **ì „ë¬¸ê°€ ì–´ì¡°**: í¬ë¦¬ì—ì´í„°ê°€ ë°”ë¡œ ì´¬ì˜ì— ë“¤ì–´ê°ˆ ìˆ˜ ìˆë„ë¡ ëª…í™•í•œ ì§€ì¹¨ì„ ì£¼ì„¸ìš”."""

    def _build_structural_summary(self, analysis: VideoAnalysisResult, case_number: int = None) -> str:
        """ì˜ìƒ ì „ì²´ì˜ êµ¬ì¡°ì  íŠ¹ì§•ì„ ìš”ì•½í•˜ì—¬ í”„ë¡¬í”„íŠ¸ ì»¨í…ìŠ¤íŠ¸ ìƒì„±"""
        title_info = f" ({analysis.video_title})" if analysis.video_title else ""
        duration_info = f" [ê¸¸ì´: {analysis.video_duration}]" if analysis.video_duration else ""
        
        # ì‚¬ë¡€ ë²ˆí˜¸ê°€ ìˆìœ¼ë©´ "ì‚¬ë¡€ N" í˜•íƒœë¡œ í‘œì‹œ, ì—†ìœ¼ë©´ ê¸°ì¡´ í˜•íƒœ ìœ ì§€
        if case_number:
            header = f"=== ì‚¬ë¡€ {case_number}:{title_info}{duration_info} ==="
        else:
            header = f"=== ì˜ìƒ ID: {analysis.video_id}{title_info}{duration_info} ë¶„ì„ ë°ì´í„° ==="
        
        lines = [header]
        
        # 1. íƒ€ì„ë¼ì¸ ê¸°ë°˜ êµ¬ì¡° (ëŒ€ë³¸ + ì‹œê°)
        lines.append("[íƒ€ì„ë¼ì¸ë³„ ì „ê°œ ë° ì—°ì¶œ]")
        
        segments = analysis.transcript_segments
        frames = analysis.visual_frames
        
        # ìŠ¤í¬ë¦½íŠ¸ì™€ ì‹œê° ì •ë³´ë¥¼ ì‹œê°„ìˆœìœ¼ë¡œ ë³‘í•©í•˜ì—¬ ì „ê°œ íë¦„ êµ¬ì„±
        # 30ì´ˆ ë‹¨ìœ„ë¡œ ë¬¶ì–´ì„œ íë¦„ íŒŒì•… (í† í° ì ˆì•½ ë° êµ¬ì¡°í™”)
        duration = segments[-1].end if segments else 0
        interval = 30.0 
        
        current_time = 0.0
        while current_time < duration:
            end_time = current_time + interval
            
            # í•´ë‹¹ êµ¬ê°„ ìŠ¤í¬ë¦½íŠ¸ ìš”ì•½
            texts = [s.text for s in segments if s.start >= current_time and s.start < end_time]
            section_text = " ".join(texts)
            if len(section_text) > 200: section_text = section_text[:200] + "..." # ë„ˆë¬´ ê¸¸ë©´ ìë¦„
            
            # í•´ë‹¹ êµ¬ê°„ ì‹œê° ì •ë³´ ìš”ì•½ (ì£¼ìš” ê°ì²´)
            section_frames = [f for f in frames if f.timestamp >= current_time and f.timestamp < end_time]
            objects = []
            for f in section_frames:
                 objects.extend([o.class_name for o in f.objects])
            
            # ê°€ì¥ ë§ì´ ë“±ì¥í•œ ê°ì²´ top 3
            from collections import Counter
            common_objects = [obj for obj, _ in Counter(objects).most_common(3)]
            
            if section_text or common_objects:
                visual_desc = f", ì£¼ìš” ì‹œê°ìš”ì†Œ: {', '.join(common_objects)}" if common_objects else ""
                lines.append(f"- {current_time:.0f}s~{end_time:.0f}s: (ë‚´ìš©) {section_text}{visual_desc}")
            
            current_time += interval
            
        return "\n".join(lines)
